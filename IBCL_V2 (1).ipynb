{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "71P4avFut2Jl"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import shuffle\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization, Activation, GlobalAveragePooling2D\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from google.colab import drive\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.applications import MobileNetV2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gTHE5P5nvRFn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e21b3bc4-9f2e-4ceb-932e-f43e69365afb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# Step 1: Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Step 2: Define dataset paths\n",
        "base_path = \"/content/drive/My Drive/Dataset\"\n",
        "folders = [\"Armyworms\", \"Cabbage Loopers\"]\n",
        "folder_paths = [os.path.join(base_path, folder) for folder in folders]\n",
        "\n",
        "# Step 3: Initialize images and labels lists\n",
        "images = []\n",
        "labels = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GPj7or1-ixzy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4746a3b9-fd2c-4eec-f084-3d138bd83bdb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading Armyworms: 100%|██████████| 96/96 [00:01<00:00, 51.18it/s]\n",
            "Loading Cabbage Loopers: 100%|██████████| 104/104 [00:01<00:00, 63.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n"
          ]
        }
      ],
      "source": [
        "# Step 4: Function to load images\n",
        "def load_images_from_folder(folder_path, label, images_list, labels_list):\n",
        "    for filename in tqdm(os.listdir(folder_path), desc=f\"Loading {os.path.basename(folder_path)}\"):\n",
        "        file_path = os.path.join(folder_path, filename)\n",
        "        img = cv2.imread(file_path)\n",
        "\n",
        "        if img is not None:\n",
        "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Convert to RGB\n",
        "            img = cv2.resize(img, (224, 224))  # Resize to (224, 224)\n",
        "            images_list.append(img)\n",
        "            labels_list.append(label)\n",
        "\n",
        "# Step 5: Load images with labels\n",
        "for label, folder in enumerate(folder_paths):\n",
        "    load_images_from_folder(folder, label, images, labels)\n",
        "\n",
        "# Step 6: Convert lists to NumPy arrays and normalize\n",
        "images = np.array(images, dtype=np.float32) / 255.0  # Normalize pixel values\n",
        "labels = np.array(labels)\n",
        "print(labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nKi7HEy8pnqt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d216bc5c-44e3-45ce-8a08-7ceab818f66b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Labels: [0 0 1 1 0 1 0 0 1 1 1 1 0 0 0 0 0 0 0 1 0 1 1 1 0 1 1 0 0 1 1 0 1 1 1 0 1\n",
            " 1 0 0 1 0 0 1 1 0 0 1 1 1 0 0 1 1 0 1 1 1 1 1 1 0 0 0 1 0 0 1 1 0 1 1 0 1\n",
            " 1 0 1 1 1 0 0 0 1 1 1 0 0 0 1 1 0 0 1 1 0 0 1 0 0 1 1 1 1 0 0 1 1 0 1 1 0\n",
            " 1 0 0 1 0 0 1 1 1 0 0 1 1 0 1 0 0 0 1 0 0 1 0 1 0 1 0 1 1 1 1 0 0 0 0 1 0\n",
            " 0 1 1 0 0 0 0 1 1 0 0 1 1 1 1 0 0 1 0 1 0 0 0 0 0 1 1 1 0 1 1 0 0 1 1 1 1\n",
            " 1 1 0 0 1 1 0 1 0 1 0 0 1 1]\n"
          ]
        }
      ],
      "source": [
        "# Step 7: Shuffle\n",
        "images, labels = shuffle(images, labels, random_state=42)\n",
        "\n",
        "# Step 8: Confirm labels\n",
        "print(\"Labels:\", labels)\n",
        "\n",
        "# Step 9: Split\n",
        "X, Y = images, labels\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QNN-3dNLpp3U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be6be954-5559-4128-c218-8e2535c4ebb9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Fold 1/5 ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 2s/step - accuracy: 0.4389 - loss: 0.8506 - val_accuracy: 0.5250 - val_loss: 0.7415 - learning_rate: 5.0000e-04\n",
            "Epoch 2/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2s/step - accuracy: 0.4742 - loss: 0.8088 - val_accuracy: 0.6000 - val_loss: 0.6750 - learning_rate: 5.0000e-04\n",
            "Epoch 3/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2s/step - accuracy: 0.5831 - loss: 0.6821 - val_accuracy: 0.6750 - val_loss: 0.6356 - learning_rate: 5.0000e-04\n",
            "Epoch 4/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2s/step - accuracy: 0.6361 - loss: 0.6380 - val_accuracy: 0.7000 - val_loss: 0.6145 - learning_rate: 5.0000e-04\n",
            "Epoch 5/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2s/step - accuracy: 0.6724 - loss: 0.5988 - val_accuracy: 0.7250 - val_loss: 0.5880 - learning_rate: 5.0000e-04\n",
            "Epoch 6/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - accuracy: 0.7431 - loss: 0.5163 - val_accuracy: 0.7250 - val_loss: 0.5671 - learning_rate: 5.0000e-04\n",
            "Epoch 7/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2s/step - accuracy: 0.7124 - loss: 0.5615 - val_accuracy: 0.7500 - val_loss: 0.5432 - learning_rate: 5.0000e-04\n",
            "Epoch 8/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2s/step - accuracy: 0.8086 - loss: 0.4270 - val_accuracy: 0.7750 - val_loss: 0.5220 - learning_rate: 5.0000e-04\n",
            "Epoch 9/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2s/step - accuracy: 0.8434 - loss: 0.3939 - val_accuracy: 0.7750 - val_loss: 0.5052 - learning_rate: 5.0000e-04\n",
            "Epoch 10/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2s/step - accuracy: 0.8077 - loss: 0.4249 - val_accuracy: 0.7750 - val_loss: 0.4965 - learning_rate: 5.0000e-04\n",
            "Epoch 11/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2s/step - accuracy: 0.8353 - loss: 0.3588 - val_accuracy: 0.7750 - val_loss: 0.4909 - learning_rate: 5.0000e-04\n",
            "Epoch 12/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2s/step - accuracy: 0.8305 - loss: 0.4506 - val_accuracy: 0.7750 - val_loss: 0.4775 - learning_rate: 5.0000e-04\n",
            "Epoch 13/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2s/step - accuracy: 0.8431 - loss: 0.3826 - val_accuracy: 0.8250 - val_loss: 0.4648 - learning_rate: 5.0000e-04\n",
            "Epoch 14/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2s/step - accuracy: 0.8406 - loss: 0.4011 - val_accuracy: 0.8250 - val_loss: 0.4560 - learning_rate: 5.0000e-04\n",
            "Epoch 15/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2s/step - accuracy: 0.8554 - loss: 0.3639 - val_accuracy: 0.8250 - val_loss: 0.4514 - learning_rate: 5.0000e-04\n",
            "Epoch 16/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2s/step - accuracy: 0.8780 - loss: 0.3483 - val_accuracy: 0.8250 - val_loss: 0.4478 - learning_rate: 5.0000e-04\n",
            "Epoch 17/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2s/step - accuracy: 0.8339 - loss: 0.3690 - val_accuracy: 0.8250 - val_loss: 0.4471 - learning_rate: 5.0000e-04\n",
            "Epoch 18/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2s/step - accuracy: 0.8879 - loss: 0.3103 - val_accuracy: 0.8500 - val_loss: 0.4417 - learning_rate: 5.0000e-04\n",
            "Epoch 19/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2s/step - accuracy: 0.8661 - loss: 0.3282 - val_accuracy: 0.8500 - val_loss: 0.4295 - learning_rate: 5.0000e-04\n",
            "Epoch 20/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2s/step - accuracy: 0.8489 - loss: 0.3365 - val_accuracy: 0.8500 - val_loss: 0.4240 - learning_rate: 5.0000e-04\n",
            "Fold 1 accuracy: 0.8500\n",
            "\n",
            "=== Fold 2/5 ===\n",
            "Epoch 1/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 3s/step - accuracy: 0.6395 - loss: 0.6549 - val_accuracy: 0.7000 - val_loss: 0.4919 - learning_rate: 5.0000e-04\n",
            "Epoch 2/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2s/step - accuracy: 0.6876 - loss: 0.6277 - val_accuracy: 0.7750 - val_loss: 0.4605 - learning_rate: 5.0000e-04\n",
            "Epoch 3/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2s/step - accuracy: 0.6987 - loss: 0.5613 - val_accuracy: 0.8000 - val_loss: 0.4354 - learning_rate: 5.0000e-04\n",
            "Epoch 4/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2s/step - accuracy: 0.7919 - loss: 0.4733 - val_accuracy: 0.8000 - val_loss: 0.4150 - learning_rate: 5.0000e-04\n",
            "Epoch 5/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2s/step - accuracy: 0.8070 - loss: 0.4481 - val_accuracy: 0.8000 - val_loss: 0.4004 - learning_rate: 5.0000e-04\n",
            "Epoch 6/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2s/step - accuracy: 0.7553 - loss: 0.4837 - val_accuracy: 0.8000 - val_loss: 0.3867 - learning_rate: 5.0000e-04\n",
            "Epoch 7/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2s/step - accuracy: 0.8319 - loss: 0.3807 - val_accuracy: 0.8000 - val_loss: 0.3732 - learning_rate: 5.0000e-04\n",
            "Epoch 8/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2s/step - accuracy: 0.8450 - loss: 0.4069 - val_accuracy: 0.8250 - val_loss: 0.3619 - learning_rate: 5.0000e-04\n",
            "Epoch 9/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2s/step - accuracy: 0.8291 - loss: 0.4213 - val_accuracy: 0.8500 - val_loss: 0.3507 - learning_rate: 5.0000e-04\n",
            "Epoch 10/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2s/step - accuracy: 0.8533 - loss: 0.3907 - val_accuracy: 0.8500 - val_loss: 0.3427 - learning_rate: 5.0000e-04\n",
            "Epoch 11/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2s/step - accuracy: 0.8413 - loss: 0.3873 - val_accuracy: 0.8500 - val_loss: 0.3367 - learning_rate: 5.0000e-04\n",
            "Epoch 12/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2s/step - accuracy: 0.8008 - loss: 0.4014 - val_accuracy: 0.8500 - val_loss: 0.3298 - learning_rate: 5.0000e-04\n",
            "Epoch 13/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2s/step - accuracy: 0.8316 - loss: 0.3882 - val_accuracy: 0.8750 - val_loss: 0.3241 - learning_rate: 5.0000e-04\n",
            "Epoch 14/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2s/step - accuracy: 0.8596 - loss: 0.3566 - val_accuracy: 0.8750 - val_loss: 0.3202 - learning_rate: 5.0000e-04\n",
            "Epoch 15/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2s/step - accuracy: 0.8175 - loss: 0.3549 - val_accuracy: 0.8750 - val_loss: 0.3170 - learning_rate: 5.0000e-04\n",
            "Epoch 16/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2s/step - accuracy: 0.8838 - loss: 0.2936 - val_accuracy: 0.8750 - val_loss: 0.3138 - learning_rate: 5.0000e-04\n",
            "Epoch 17/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2s/step - accuracy: 0.8128 - loss: 0.4156 - val_accuracy: 0.8750 - val_loss: 0.3093 - learning_rate: 5.0000e-04\n",
            "Epoch 18/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2s/step - accuracy: 0.8514 - loss: 0.3072 - val_accuracy: 0.8750 - val_loss: 0.3062 - learning_rate: 5.0000e-04\n",
            "Epoch 19/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 2s/step - accuracy: 0.8732 - loss: 0.2933 - val_accuracy: 0.8750 - val_loss: 0.3046 - learning_rate: 5.0000e-04\n",
            "Epoch 20/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2s/step - accuracy: 0.8997 - loss: 0.2877 - val_accuracy: 0.8750 - val_loss: 0.3035 - learning_rate: 5.0000e-04\n",
            "Fold 2 accuracy: 0.8750\n",
            "\n",
            "=== Fold 3/5 ===\n",
            "Epoch 1/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 2s/step - accuracy: 0.6051 - loss: 0.7344 - val_accuracy: 0.7750 - val_loss: 0.5205 - learning_rate: 5.0000e-04\n",
            "Epoch 2/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2s/step - accuracy: 0.6283 - loss: 0.6788 - val_accuracy: 0.7750 - val_loss: 0.4922 - learning_rate: 5.0000e-04\n",
            "Epoch 3/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2s/step - accuracy: 0.6859 - loss: 0.5944 - val_accuracy: 0.8250 - val_loss: 0.4621 - learning_rate: 5.0000e-04\n",
            "Epoch 4/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2s/step - accuracy: 0.6990 - loss: 0.5775 - val_accuracy: 0.8750 - val_loss: 0.4346 - learning_rate: 5.0000e-04\n",
            "Epoch 5/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2s/step - accuracy: 0.7009 - loss: 0.5177 - val_accuracy: 0.9000 - val_loss: 0.4156 - learning_rate: 5.0000e-04\n",
            "Epoch 6/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2s/step - accuracy: 0.7757 - loss: 0.5073 - val_accuracy: 0.9250 - val_loss: 0.3962 - learning_rate: 5.0000e-04\n",
            "Epoch 7/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2s/step - accuracy: 0.7423 - loss: 0.4715 - val_accuracy: 0.9000 - val_loss: 0.3802 - learning_rate: 5.0000e-04\n",
            "Epoch 8/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2s/step - accuracy: 0.8089 - loss: 0.4784 - val_accuracy: 0.9250 - val_loss: 0.3674 - learning_rate: 5.0000e-04\n",
            "Epoch 9/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2s/step - accuracy: 0.7788 - loss: 0.4495 - val_accuracy: 0.9250 - val_loss: 0.3563 - learning_rate: 5.0000e-04\n",
            "Epoch 10/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2s/step - accuracy: 0.8697 - loss: 0.3592 - val_accuracy: 0.9250 - val_loss: 0.3463 - learning_rate: 5.0000e-04\n",
            "Epoch 11/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2s/step - accuracy: 0.8313 - loss: 0.4231 - val_accuracy: 0.9250 - val_loss: 0.3375 - learning_rate: 5.0000e-04\n",
            "Epoch 12/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2s/step - accuracy: 0.8378 - loss: 0.4118 - val_accuracy: 0.9250 - val_loss: 0.3301 - learning_rate: 5.0000e-04\n",
            "Epoch 13/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2s/step - accuracy: 0.8451 - loss: 0.3600 - val_accuracy: 0.9250 - val_loss: 0.3247 - learning_rate: 5.0000e-04\n",
            "Epoch 14/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2s/step - accuracy: 0.8482 - loss: 0.3387 - val_accuracy: 0.9250 - val_loss: 0.3195 - learning_rate: 5.0000e-04\n",
            "Epoch 15/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2s/step - accuracy: 0.8818 - loss: 0.3705 - val_accuracy: 0.9250 - val_loss: 0.3120 - learning_rate: 5.0000e-04\n",
            "Epoch 16/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2s/step - accuracy: 0.8448 - loss: 0.3604 - val_accuracy: 0.9250 - val_loss: 0.3057 - learning_rate: 5.0000e-04\n",
            "Epoch 17/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2s/step - accuracy: 0.8676 - loss: 0.3655 - val_accuracy: 0.9250 - val_loss: 0.3018 - learning_rate: 5.0000e-04\n",
            "Epoch 18/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2s/step - accuracy: 0.8761 - loss: 0.3426 - val_accuracy: 0.9250 - val_loss: 0.2990 - learning_rate: 5.0000e-04\n",
            "Epoch 19/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2s/step - accuracy: 0.8935 - loss: 0.2919 - val_accuracy: 0.9250 - val_loss: 0.2967 - learning_rate: 5.0000e-04\n",
            "Epoch 20/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2s/step - accuracy: 0.9125 - loss: 0.3061 - val_accuracy: 0.9250 - val_loss: 0.2948 - learning_rate: 5.0000e-04\n",
            "Fold 3 accuracy: 0.9250\n",
            "\n",
            "=== Fold 4/5 ===\n",
            "Epoch 1/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2s/step - accuracy: 0.5105 - loss: 0.8903 - val_accuracy: 0.4750 - val_loss: 0.6941 - learning_rate: 5.0000e-04\n",
            "Epoch 2/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2s/step - accuracy: 0.4950 - loss: 0.8442 - val_accuracy: 0.6000 - val_loss: 0.6942 - learning_rate: 5.0000e-04\n",
            "Epoch 3/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2s/step - accuracy: 0.5318 - loss: 0.7758 - val_accuracy: 0.6000 - val_loss: 0.6641 - learning_rate: 5.0000e-04\n",
            "Epoch 4/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2s/step - accuracy: 0.6566 - loss: 0.6412 - val_accuracy: 0.6750 - val_loss: 0.6193 - learning_rate: 5.0000e-04\n",
            "Epoch 5/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2s/step - accuracy: 0.6544 - loss: 0.5993 - val_accuracy: 0.7250 - val_loss: 0.5722 - learning_rate: 5.0000e-04\n",
            "Epoch 6/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2s/step - accuracy: 0.6774 - loss: 0.6424 - val_accuracy: 0.7750 - val_loss: 0.5378 - learning_rate: 5.0000e-04\n",
            "Epoch 7/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2s/step - accuracy: 0.6652 - loss: 0.5908 - val_accuracy: 0.7750 - val_loss: 0.5182 - learning_rate: 5.0000e-04\n",
            "Epoch 8/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2s/step - accuracy: 0.7151 - loss: 0.5448 - val_accuracy: 0.7750 - val_loss: 0.5028 - learning_rate: 5.0000e-04\n",
            "Epoch 9/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2s/step - accuracy: 0.8250 - loss: 0.4370 - val_accuracy: 0.8000 - val_loss: 0.4912 - learning_rate: 5.0000e-04\n",
            "Epoch 10/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2s/step - accuracy: 0.8198 - loss: 0.4410 - val_accuracy: 0.8000 - val_loss: 0.4790 - learning_rate: 5.0000e-04\n",
            "Epoch 11/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2s/step - accuracy: 0.8008 - loss: 0.4224 - val_accuracy: 0.8000 - val_loss: 0.4656 - learning_rate: 5.0000e-04\n",
            "Epoch 12/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2s/step - accuracy: 0.8001 - loss: 0.4086 - val_accuracy: 0.8000 - val_loss: 0.4578 - learning_rate: 5.0000e-04\n",
            "Epoch 13/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2s/step - accuracy: 0.7717 - loss: 0.4521 - val_accuracy: 0.7750 - val_loss: 0.4462 - learning_rate: 5.0000e-04\n",
            "Epoch 14/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2s/step - accuracy: 0.7844 - loss: 0.4179 - val_accuracy: 0.7750 - val_loss: 0.4342 - learning_rate: 5.0000e-04\n",
            "Epoch 15/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2s/step - accuracy: 0.8235 - loss: 0.3820 - val_accuracy: 0.7750 - val_loss: 0.4240 - learning_rate: 5.0000e-04\n",
            "Epoch 16/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2s/step - accuracy: 0.8449 - loss: 0.3832 - val_accuracy: 0.7750 - val_loss: 0.4196 - learning_rate: 5.0000e-04\n",
            "Epoch 17/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2s/step - accuracy: 0.8151 - loss: 0.3785 - val_accuracy: 0.7750 - val_loss: 0.4187 - learning_rate: 5.0000e-04\n",
            "Epoch 18/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2s/step - accuracy: 0.8203 - loss: 0.3871 - val_accuracy: 0.7750 - val_loss: 0.4121 - learning_rate: 5.0000e-04\n",
            "Epoch 19/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2s/step - accuracy: 0.8201 - loss: 0.3671 - val_accuracy: 0.7750 - val_loss: 0.4099 - learning_rate: 5.0000e-04\n",
            "Epoch 20/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2s/step - accuracy: 0.8318 - loss: 0.3685 - val_accuracy: 0.8000 - val_loss: 0.4025 - learning_rate: 5.0000e-04\n",
            "Fold 4 accuracy: 0.8000\n",
            "\n",
            "=== Fold 5/5 ===\n",
            "Epoch 1/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 3s/step - accuracy: 0.5387 - loss: 0.8309 - val_accuracy: 0.6154 - val_loss: 0.6363 - learning_rate: 5.0000e-04\n",
            "Epoch 2/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2s/step - accuracy: 0.5517 - loss: 0.7456 - val_accuracy: 0.7179 - val_loss: 0.5715 - learning_rate: 5.0000e-04\n",
            "Epoch 3/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2s/step - accuracy: 0.6059 - loss: 0.6799 - val_accuracy: 0.7692 - val_loss: 0.5144 - learning_rate: 5.0000e-04\n",
            "Epoch 4/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2s/step - accuracy: 0.6424 - loss: 0.6582 - val_accuracy: 0.8462 - val_loss: 0.4678 - learning_rate: 5.0000e-04\n",
            "Epoch 5/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2s/step - accuracy: 0.7042 - loss: 0.5627 - val_accuracy: 0.8462 - val_loss: 0.4281 - learning_rate: 5.0000e-04\n",
            "Epoch 6/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2s/step - accuracy: 0.6762 - loss: 0.5801 - val_accuracy: 0.8462 - val_loss: 0.3902 - learning_rate: 5.0000e-04\n",
            "Epoch 7/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2s/step - accuracy: 0.6832 - loss: 0.5693 - val_accuracy: 0.8718 - val_loss: 0.3592 - learning_rate: 5.0000e-04\n",
            "Epoch 8/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2s/step - accuracy: 0.7320 - loss: 0.4536 - val_accuracy: 0.8974 - val_loss: 0.3338 - learning_rate: 5.0000e-04\n",
            "Epoch 9/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2s/step - accuracy: 0.7902 - loss: 0.4998 - val_accuracy: 0.8974 - val_loss: 0.3130 - learning_rate: 5.0000e-04\n",
            "Epoch 10/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2s/step - accuracy: 0.8625 - loss: 0.4040 - val_accuracy: 0.9231 - val_loss: 0.2950 - learning_rate: 5.0000e-04\n",
            "Epoch 11/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2s/step - accuracy: 0.7708 - loss: 0.4757 - val_accuracy: 0.9231 - val_loss: 0.2794 - learning_rate: 5.0000e-04\n",
            "Epoch 12/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2s/step - accuracy: 0.7989 - loss: 0.4083 - val_accuracy: 0.9231 - val_loss: 0.2664 - learning_rate: 5.0000e-04\n",
            "Epoch 13/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2s/step - accuracy: 0.8715 - loss: 0.3679 - val_accuracy: 0.9231 - val_loss: 0.2541 - learning_rate: 5.0000e-04\n",
            "Epoch 14/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2s/step - accuracy: 0.8536 - loss: 0.3889 - val_accuracy: 0.9231 - val_loss: 0.2428 - learning_rate: 5.0000e-04\n",
            "Epoch 15/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2s/step - accuracy: 0.8549 - loss: 0.3298 - val_accuracy: 0.9231 - val_loss: 0.2339 - learning_rate: 5.0000e-04\n",
            "Epoch 16/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2s/step - accuracy: 0.8665 - loss: 0.3830 - val_accuracy: 0.9231 - val_loss: 0.2263 - learning_rate: 5.0000e-04\n",
            "Epoch 17/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2s/step - accuracy: 0.8886 - loss: 0.3298 - val_accuracy: 0.9231 - val_loss: 0.2189 - learning_rate: 5.0000e-04\n",
            "Epoch 18/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2s/step - accuracy: 0.8693 - loss: 0.3219 - val_accuracy: 0.9231 - val_loss: 0.2111 - learning_rate: 5.0000e-04\n",
            "Epoch 19/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2s/step - accuracy: 0.8984 - loss: 0.2927 - val_accuracy: 0.9231 - val_loss: 0.2049 - learning_rate: 5.0000e-04\n",
            "Epoch 20/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2s/step - accuracy: 0.8872 - loss: 0.2882 - val_accuracy: 0.9231 - val_loss: 0.1981 - learning_rate: 5.0000e-04\n",
            "Fold 5 accuracy: 0.9231\n",
            "\n",
            "K‑Fold results: [0.8500000238418579, 0.875, 0.925000011920929, 0.800000011920929, 0.9230769276618958]\n",
            "Average accuracy: 0.8746153950691223\n"
          ]
        }
      ],
      "source": [
        "# Step 9: Prepare for K‑Fold\n",
        "X, Y = images, labels\n",
        "k = 5\n",
        "skf = StratifiedKFold(n_splits=k, shuffle=True, random_state=42)\n",
        "fold_accuracies = []\n",
        "\n",
        "for fold, (train_idx, val_idx) in enumerate(skf.split(X, Y), start=1):\n",
        "    print(f\"\\n=== Fold {fold}/{k} ===\")\n",
        "    X_train, X_val = X[train_idx], X[val_idx]\n",
        "    Y_train, Y_val = Y[train_idx], Y[val_idx]\n",
        "\n",
        "    # Data augmentation for this fold\n",
        "    datagen = ImageDataGenerator(\n",
        "        rotation_range=30,\n",
        "        width_shift_range=0.2,\n",
        "        height_shift_range=0.2,\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.2,\n",
        "        horizontal_flip=True,\n",
        "        fill_mode='nearest'\n",
        "    )\n",
        "    train_gen = datagen.flow(X_train, Y_train, batch_size=32)\n",
        "\n",
        "    # Load base model\n",
        "    base_model = MobileNetV2(include_top=False, input_shape=(224, 224, 3), weights='imagenet')\n",
        "    base_model.trainable = False  # Freeze base layers\n",
        "\n",
        "    # Custom head\n",
        "    x = base_model.output\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    x = Dropout(0.3)(x)\n",
        "    output = Dense(1, activation='sigmoid')(x)\n",
        "    model = Model(inputs=base_model.input, outputs=output)\n",
        "\n",
        "    # Compile model\n",
        "    model.compile(optimizer=Adam(learning_rate=0.0005),\n",
        "                  loss='binary_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    # Train\n",
        "    model.fit(train_gen,\n",
        "              validation_data=(X_val, Y_val),\n",
        "              epochs=20,\n",
        "              callbacks=[\n",
        "                  EarlyStopping(patience=5, restore_best_weights=True),\n",
        "                  ReduceLROnPlateau(patience=3)\n",
        "              ],\n",
        "              verbose=1)\n",
        "\n",
        "    # Evaluate\n",
        "    _, acc = model.evaluate(X_val, Y_val, verbose=0)\n",
        "    print(f\"Fold {fold} accuracy: {acc:.4f}\")\n",
        "    fold_accuracies.append(acc)\n",
        "\n",
        "# Final results\n",
        "print(\"\\nK‑Fold results:\", fold_accuracies)\n",
        "print(\"Average accuracy:\", np.mean(fold_accuracies))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lt575QvgacqN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52e86b5c-8782-49a3-ac96-450113716656"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 273ms/step - accuracy: 0.9175 - loss: 0.2064\n",
            "Test accurancy: 0.923077\n",
            "Test loss: 0.198063\n"
          ]
        }
      ],
      "source": [
        "loss,acc = model.evaluate(X_val,Y_val, verbose=1)\n",
        "print(f\"Test accurancy: {acc:4f}\")\n",
        "print(f\"Test loss: {loss:4f}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}